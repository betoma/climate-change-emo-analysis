{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexipaths = {\n",
    "    \"VAD\": \"NRC-VAD-Lexicon/NRC-VAD-Lexicon.txt\",\n",
    "    \"emotion\": \"NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\",\n",
    "    \"affect intensity\": \"NRC-Affect-Intensity-Lexicon/NRC-AffectIntensity-Lexicon.txt\"\n",
    "}\n",
    "big_folder = \"NRC-Sentiment-Emotion-Lexicons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emo:\n",
    "    def __init__(self,lexicon_paths:dict=lexipaths,overfolder:str=big_folder):\n",
    "        self.tknzr = TweetTokenizer()\n",
    "        self.lexicons = {}\n",
    "        for lex in lexicon_paths:\n",
    "            filename = \"../{}/{}\".format(overfolder,lexicon_paths[lex])\n",
    "            with open(filename,\"r\",encoding=\"utf-8\") as f:\n",
    "                if lex == \"emotion\":\n",
    "                    self.lexicons[lex] = pd.read_csv(f,sep=\"\\t\",index_col=[\"Word\",\"Sense\"])\n",
    "                elif lex == \"affect intensity\":\n",
    "                    self.lexicons[lex] = pd.read_csv(f,sep=\"\\t\",index_col=[\"Word\",\"AffectDimension\"])\n",
    "                else:\n",
    "                    self.lexicons[lex] = pd.read_csv(f,sep=\"\\t\",index_col=\"Word\")\n",
    "\n",
    "    def classify_sentence(self,\n",
    "        sentence:\"\"\"string or list of words\"\"\",\n",
    "        database:\"\"\"one of VAD, emotion, or affect intensity\"\"\",\n",
    "        tokenize:bool=True\n",
    "        ):\n",
    "        if database == \"emotion\":\n",
    "            values = {\n",
    "                \"anger\": 0,\n",
    "                \"anticipation\": 0,\n",
    "                \"disgust\": 0,\n",
    "                \"fear\": 0,\n",
    "                \"joy\": 0,\n",
    "                \"sadness\": 0,\n",
    "                \"surprise\": 0,\n",
    "                \"trust\": 0\n",
    "            }\n",
    "        elif database == \"VAD\":\n",
    "            values = {\n",
    "                \"Valence\": 0,\n",
    "                \"Arousal\": 0,\n",
    "                \"Dominance\": 0\n",
    "            }\n",
    "        elif database == \"affect intensity\":\n",
    "            values = {\n",
    "                \"anger\": 0,\n",
    "                \"fear\": 0,\n",
    "                \"joy\": 0,\n",
    "                \"sadness\": 0\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(\"database must be one of VAD, emotion, or affect intensity\")\n",
    "        df = self.lexicons[database]\n",
    "        words_factored = 0\n",
    "        if tokenize:\n",
    "            bag_of_words = self.tknzr.tokenize(sentence)\n",
    "        else:\n",
    "            if type(sentence) is str:\n",
    "                bag_of_words = sentence.split()\n",
    "            else:\n",
    "                bag_of_words = sentence\n",
    "        for word in bag_of_words:\n",
    "            word = word.lower()\n",
    "            try:\n",
    "                word_values = df.loc[word]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            else:\n",
    "                words_factored += 1\n",
    "                for key in values:\n",
    "                    if database == \"VAD\":\n",
    "                        values[key] += df.loc[word,key]\n",
    "                    elif database == \"emotion\":\n",
    "                        values[key] += df.loc[(word,key),'Score']\n",
    "                    elif database == \"affect intensity\":\n",
    "                        try:\n",
    "                            v = df.loc[(word,key),'Score']\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                        else:\n",
    "                            values[key] += v\n",
    "        if words_factored == 0:\n",
    "            print(\"No words from this sentence found in lexicon.\")\n",
    "            return None\n",
    "        return {key:(values[key]/words_factored) for key in values}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Valence': 0.073, 'Arousal': 0.784, 'Dominance': 0.431}"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "emojudge = Emo()\n",
    "emojudge.classify_sentence(\"Damn it!\",\"VAD\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "bertfine",
   "display_name": "Python 3 (bertfine virtual environment)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}