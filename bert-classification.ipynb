{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Dataset\n",
    "from transformers import WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier on Labelled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "MODEL_NAME = \"./classification-outputs/\"\n",
    "\n",
    "TRAIN_DATA_FILE = \"\"\n",
    "TRAIN_LABEL_FILE = \"\"\n",
    "VAL_DATA_FILE = \"\"\n",
    "VAL_LABEL_FILE = \"\"\n",
    "OUTPUT_DIR = \"./classification-outputs\"\n",
    "\n",
    "MAX_LENGTH = int(64)\n",
    "RANDOM_SEED = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PARAMS = {\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 1e-5,\n",
    "    'weight_decay': 1e-5,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'max_grad_norm': 1.0,\n",
    "    'grad_accum_steps': 1,\n",
    "    'warmup_steps': 500,\n",
    "    'checkpoint_steps': 500,\n",
    "    'checkpoint_dir': OUTPUT_DIR,\n",
    "    'eval_steps': 250,\n",
    "    'num_train_epochs': 1,\n",
    "    'max_steps': -1, # if >0, overrides num_train_epochs\n",
    "    'checkpoint': MODEL_NAME if MODEL_NAME.endswith('.pt') else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = BertConfig.from_pretrained(MODEL_NAME)\n",
    "CONFIG.num_labels = 3\n",
    "TOKENIZER = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case = False, config = CONFIG)\n",
    "MODEL = BertForSequenceClassification.from_pretrained(MODEL_NAME, config = CONFIG)\n",
    "\n",
    "#MODEL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"number of parameters in the model={count_parameters(MODEL)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemEvalDataset(Dataset):\n",
    "    def __init__(self, source_path: str, target_path: str, tokenizer = TOKENIZER, block_size = MAX_LENGTH):\n",
    "        assert os.path.isfile(source_path)\n",
    "        assert os.path.isfile(target_path)\n",
    "        print(f\"Creating features from source dataset file at {source_path}\")\n",
    "        print(f\"Creating features from target label file at {target_path}\")\n",
    "        \n",
    "        with open(source_path) as f:\n",
    "            source = [line.strip() for line in f.readlines()]\n",
    "        with open(target_path) as f:\n",
    "            target = [line.strip() for line in f.readlines()]\n",
    "        assert len(source) == len(target)\n",
    "        \n",
    "        self.ids = []\n",
    "        self.masks = []\n",
    "        self.labels = [int(line) for line in target]\n",
    "        \n",
    "        for line in tqdm(source, leave = False):\n",
    "            tokenized_text = tokenizer.encode(line, max_length = block_size, pad_to_max_length = True)\n",
    "            self.ids.append(tokenized_text)\n",
    "            self.masks.append([int(token_id > 0) for token_id in tokenized_text])\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return torch.tensor(self.ids[i]), torch.tensor(self.masks[i]), torch.tensor(self.labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, model, tokenizer, batch_size, key, max_steps = None, device = torch.device('cpu')):\n",
    "    sampler = SequentialSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler = sampler, batch_size = batch_size)\n",
    "    \n",
    "    print(f\"Beginning evaluation on dataset {key}\")\n",
    "    \n",
    "    eval_loss = 0.0\n",
    "    num_steps = 0\n",
    "    preds = []\n",
    "    targets = []\n",
    "    \n",
    "    iterator = tqdm(dataloader, desc='evaluating', leave = False, total = max_steps)\n",
    "    \n",
    "    for batch in iterator:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2].unsqueeze(0)}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss, logits = outputs[:2]\n",
    "            eval_loss += loss.mean().item()\n",
    "        num_steps += 1\n",
    "        \n",
    "        preds.extend([np.argmax(x) for x in logits.detach().cpu().numpy()])\n",
    "        targets.extend(inputs['labels'].detach().cpu().numpy()[0])\n",
    "        \n",
    "        if max_steps:\n",
    "            if num_steps >= max_steps:\n",
    "                iterator.close()\n",
    "                break\n",
    "        \n",
    "        eval_loss = eval_loss / num_steps\n",
    "        \n",
    "        y_true, y_pred = np.array(targets), np.array(preds)\n",
    "        accuracy = accuracy_score(y_true, y_pred, sample_weight=None)\n",
    "        \n",
    "        print(f'accuracy:{accuracy}')\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model = MODEL, tokenizer = TOKENIZER, params = TRAIN_PARAMS, val_dataset = None, device = torch.device('cpu')):\n",
    "    sampler = RandomSampler(dataset)\n",
    "    dataloader = DataLoader(dataset, sampler = sampler, batch_size = params['batch_size'])\n",
    "    \n",
    "    if params['max_steps'] > 0:\n",
    "        total_steps = params['max_steps']\n",
    "        num_epochs = params['max_steps'] // len(dataloader) // params['grad_accum_steps'] + 1\n",
    "    else:\n",
    "        total_steps = len(dataloader) // params['grad_accum_steps'] * params['num_train_epochs']\n",
    "        num_epochs = params['num_train_epochs']\n",
    "    \n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_params = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': params['weight_decay']},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_params, lr = params['learning_rate'], eps = params['adam_epsilon'])\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = params['warmup_steps'], num_training_steps = total_steps)\n",
    "    \n",
    "    print('training...')\n",
    "    print(f\"num examples = \\t\\t\\t{len(dataset)}\")\n",
    "    print(f\"num epochs = \\t\\t\\t{num_epochs}\")\n",
    "    \n",
    "    if params['grad_accum_steps'] > 1:\n",
    "        print(f\"gradient accumulation steps = \\t{params['grad_accum_steps']}\")\n",
    "        print(f\"batch size with accumulation = \\t{params['batch_size']}\")\n",
    "    else:\n",
    "        print(f\"batch size = \\t\\t\\t{params['batch_size']}\")\n",
    "        print(f\"total optimization steps = \\t{total_steps}\")\n",
    "    \n",
    "    global_steps = 0\n",
    "    epochs_trained = 0\n",
    "    steps_trained_in_current_epoch = 0\n",
    "    \n",
    "    if params['checkpoint']:\n",
    "        opt_path = os.path.join(params['checkpoint'], 'optimizer.pt')\n",
    "        sch_path = os.path.join(params['checkpoint'], 'scheduler.pt')\n",
    "        if os.path.isfile(opt_path) and os.path.isfile(sch_path):\n",
    "            print(\"\\nupdating optimizer and scheduler from checkpoint\")\n",
    "            optimizer.load_state_dict(torch.load(opt_path))\n",
    "            scheduler.load_state_dict(torch.load(sch_path))\n",
    "        \n",
    "        try:\n",
    "            global_step = int(params['checkpoint'].split('-')[-1].split('/')[0])\n",
    "            epochs_trained = global_step // len(dataloader) // params['grad_accum_steps']\n",
    "            steps_trained_in_current_epoch = global_step % (len(dataloader) // params['grad_accum_steps'])\n",
    "            print(f\"\\npicking up from checkpoint at global step:\\t{global_step}\")\n",
    "            print(f\"continuing training from epoch:\\t{epochs_trained}\")\n",
    "            print(f\"skipping first steps in epoch:\\t\\t{steps_trained_in_current_epoch}\")\n",
    "        except ValueError:\n",
    "            print('could not update current steps/epoch form checkpoint name')\n",
    "    \n",
    "    train_loss, logging_loss = 0.0, 0.0\n",
    "    \n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.zero_grad()\n",
    "    \n",
    "    train_iterator = trange(epochs_trained, num_epochs, desc='epoch')\n",
    "    \n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(dataloader, desc='iteration')\n",
    "        \n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            if steps_trained_in_current_epoch > 0:\n",
    "                steps_trained_in_current_epoch -= 1\n",
    "                continue\n",
    "            \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "            \n",
    "            model.train()\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            \n",
    "            if params['grad_accum_steps'] > 1:\n",
    "                loss = loss / params['grad_accum_steps']\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if (step+1) % params['grad_accum_steps'] == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), params['max_grad_norm'])\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "                \n",
    "                if params['checkpoint_steps'] > 0 and global_step % params['checkpoint_steps'] == 0:\n",
    "                    save_path = os.path.join(params['checkpoint_dir'], f\"checkpoint -- {global_step}\")\n",
    "                    os.makedirs(save_path, exist_ok=True)\n",
    "                    model.save_pretrained(save_path)\n",
    "                    print(f\"saving model checkpoint to:\\t{save_path}\")\n",
    "                    torch.save(params, os.path.join(save_path, 'training_args.bin'))\n",
    "                    torch.save(optimizer.state_dict(), os.path.join(save_path, \"optimizer.pt\"))\n",
    "                    torch.save(scheduler.state_dict(), os.path.join(save_path, \"scheduler.pt\"))\n",
    "                    \n",
    "                if params['eval_steps'] > 0 and global_step % params['eval_steps'] == 0:\n",
    "                    if val_dataset:\n",
    "                        evaluate(val_dataset, model, tokenizer, params['batch_size'], 'val', device=device)\n",
    "                        evaluate(dataset, model, tokenizer, params['batch_size'], 'train', max_steps = 200, device=device)\n",
    "                    print(f\"loss:\\t\\t\\t{train_loss / global_step}\")\n",
    "                \n",
    "            if params['max_steps'] > 0 and global_step > params['max_steps']:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "        \n",
    "        if params['max_steps'] > 0 and global_step > params['max_steps']:\n",
    "            train_iterator.close()\n",
    "            break\n",
    "        \n",
    "    print(f\"saving final model to:\\t{params['checkpoint_dir']}\")\n",
    "    model.save_pretrained(params['checkpoint_dir'])\n",
    "    torch.save(params, os.path.join(param['checkpoint_dir'], 'training_args.bin'))\n",
    "    \n",
    "    return global_step, train_loss / global_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_dataset' not in globals():\n",
    "    train_dataset = SemEvalDataset(source_path = TRAIN_DATA_FILE, target_path = TRAIN_LABEL_FILE)\n",
    "    val_dataset = SemEvalDataset(source_path = VAL_DATA_FILE, target_path = VAL_LABEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_steps, train_loss = train(train_dataset, val_dataset=val_dataset, device=device)\n",
    "print(f\"global_steps={global_step}, average loss={train_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(val_dataset, MODEL, TOKENIZER, TRAIN_PARAMS['batch_size'], 'val', device=device)\n",
    "evaluate(train_dataset, MODEL, TOKENIZER, TRAIN_PARAMS['batch_size'], 'train', device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertfine",
   "language": "python",
   "name": "bertfine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}